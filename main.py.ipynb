{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3506963-64f7-49f8-9083-f0c4ef8a3bcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "main.py - Root entry point that imports and executes create_view.py from same directory\n",
    "GitHub Repo Structure:\n",
    "project/\n",
    "‚îú‚îÄ‚îÄ main.py                 # This file (entry point for Databricks Jobs)\n",
    "‚îî‚îÄ‚îÄ create_view.py          # Your notebook code saved as .py\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from pyspark.sql import SparkSession\n",
    "import logging\n",
    "import importlib.util\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"view_creator_main\")\n",
    "\n",
    "def import_create_view_module():\n",
    "    \"\"\"Import create_view.py from same directory as main.py\"\"\"\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    create_view_path = os.path.join(script_dir, \"create_view.py\")\n",
    "    \n",
    "    if not os.path.exists(create_view_path):\n",
    "        print(f\"‚ùå create_view.py not found at: {create_view_path}\")\n",
    "        print(\"üìÅ Expected GitHub structure:\")\n",
    "        print(\"   project/\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ main.py\")\n",
    "        print(\"   ‚îî‚îÄ‚îÄ create_view.py\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Add current directory to Python path\n",
    "    if script_dir not in sys.path:\n",
    "        sys.path.insert(0, script_dir)\n",
    "    \n",
    "    # Import create_view module\n",
    "    spec = importlib.util.spec_from_file_location(\"create_view\", create_view_path)\n",
    "    create_view_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(create_view_module)\n",
    "    \n",
    "    return create_view_module\n",
    "\n",
    "def main():\n",
    "    \"\"\"Parse CLI arguments and execute create_view.run()\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Create Unity Catalog VIEW - Calls create_view.py\",\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        epilog=\"\"\"\n",
    "GitHub Workflow Setup:\n",
    "1. Repo structure: main.py | create_view.py\n",
    "2. Git integration: Workspace > Repos > Add repo\n",
    "3. Job config:\n",
    "   Task Type: Spark Python\n",
    "   File: /Repos/{username}/{repo}/{branch}/main.py\n",
    "   Parameters: dataeng dataeng source_table target_view create false\n",
    "\n",
    "Examples:\n",
    "  dataeng dataeng schema_evo_merge_schema_t3 schema_evo_merge_schema_demo9 create false\n",
    "        \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\"catalog_name\", nargs=\"?\", default=\"dataeng\")\n",
    "    parser.add_argument(\"schema_name\", nargs=\"?\", default=\"dataeng\")\n",
    "    parser.add_argument(\"source_table_name\", nargs=\"?\", default=\"schema_evo_merge_schema_t3\")\n",
    "    parser.add_argument(\"target_view_name\", nargs=\"?\", default=\"schema_evo_merge_schema_demo9\")\n",
    "    parser.add_argument(\"operation\", nargs=\"?\", default=\"create\", choices=[\"create\", \"alter\"])\n",
    "    parser.add_argument(\"dryrun\", nargs=\"?\", type=str, default=\"false\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    dryrun = args.dryrun.lower() in (\"true\", \"1\", \"yes\", \"y\")\n",
    "    \n",
    "    # Validate Spark session\n",
    "    try:\n",
    "        spark = SparkSession.getActiveSession()\n",
    "        if spark is None:\n",
    "            print(\"‚ùå No Spark session. Run in Databricks.\")\n",
    "            sys.exit(1)\n",
    "    except:\n",
    "        print(\"‚ùå Spark session unavailable\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Import and execute create_view.py\n",
    "    print(\"üöÄ Importing create_view.py...\")\n",
    "    try:\n",
    "        create_view_module = import_create_view_module()\n",
    "        print(\"‚úÖ create_view.py loaded successfully\")\n",
    "        \n",
    "        print(f\"üìã Executing: {args.catalog_name}.{args.schema_name}.{args.target_view_name}\")\n",
    "        print(f\"   Source: {args.catalog_name}.{args.schema_name}.{args.source_table_name}\")\n",
    "        print(f\"   Mode: {args.operation} ({'dryrun' if dryrun else 'live'})\")\n",
    "        \n",
    "        # Call the run() function from your notebook\n",
    "        create_view_module.run(\n",
    "            spark=spark,\n",
    "            catalog_name=args.catalog_name,\n",
    "            schema_name=args.schema_name,\n",
    "            source_table_name=args.source_table_name,\n",
    "            target_view_name=args.target_view_name,\n",
    "            operation=args.operation,\n",
    "            dryrun=dryrun\n",
    "        )\n",
    "        \n",
    "        print(\"üéâ Job completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Execution failed: {e}\")\n",
    "        logger.error(f\"Error: {e}\", exc_info=True)\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b535bb6-77f8-495e-8d3b-5e6dd7f37899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /FileStore/project/main.py $dryrun=\"true\" "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
